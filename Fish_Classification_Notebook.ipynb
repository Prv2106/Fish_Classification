{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":77320,"databundleVersionId":8421301,"sourceType":"competition"},{"sourceId":8489388,"sourceType":"datasetVersion","datasetId":5064652}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets\nfrom pathlib import Path\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfish_dataset_dir = '/kaggle/input/ai-unict-2024-challenge-1/'\nfish_dataset_train_dir = '/kaggle/input/ai-unict-2024-challenge-1/train'\nfish_dataset_test_dir = '/kaggle/input/ai-unict-2024-challenge-1/test'\n\n# link to GoogleDrive folder:\ngd_folder = \"https://drive.google.com/drive/folders/1E7E0CDF98_MlKi8Mk8764cQwu004jjJZ?usp=sharing\"\n\n# link to GoogleDrive zip:\ngd_zip = \"https://drive.google.com/file/d/18O5LAK35yvTK3Ow-SZrU0p_Y-Yv3OOe0/view?usp=sharing\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setup Gdrive file download extention \n!conda install -y gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model1 weights\n!gdown --id 1F6ib68f1HarOeMkoAG1Csdt9PgcS_Y5h\n\n# Model2 weights\n!gdown --id 1GO12RFjozr9V5sqcvApOaTbCR7cG9epH\n\n# Model3 weights 1\n!gdown --id 103KBMc5iLY4SQ7vyN4xK9FwpO7t-Kn71\n# Model3 weights 2\n!gdown --id 14dze-SSp5uMos_rdDY4e1ydTfs2Y7xGQ\n\n# Model4 weights 1\n!gdown --id 1odOpmPYR2YdYJAm121PnOQaRrgb3np3D\n\n# Model4 weights 2\n!gdown --id 1Lo-2zz9Ss5HJSF_kXn3U51Fd0QS1u5gt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # **MODEL 1**\n\n**We use a pre-trained ResNet18 and fine-tune the classifier on the small annotated dataset**","metadata":{}},{"cell_type":"code","source":"class TestFishDataset(Dataset):\n    def __init__(self, data_dir, transforms=T.Compose([])):\n        self.data_dir = Path(data_dir)\n        self.transforms = transforms\n        self.files = sorted(os.listdir(self.data_dir))\n        \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, i):\n        file_path = self.data_dir / self.files[i]\n        img = Image.open(file_path).convert(\"RGB\")\n        img = self.transforms(img)\n        return img,self.files[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomRotation(degrees=30),\n        T.Resize((224,224)),\n        T.ToTensor(),\n        T.Normalize(0.5, 0.5) \n    ])\n\ntest_transforms = T.Compose([\n        T.Resize((224,224)),\n        T.ToTensor(),\n        T.Normalize(0.5, 0.5)\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denormalize_and_resize(img, size=(128, 128)):\n    img = img * 0.5 + 0.5  \n    img = T.functional.resize(img, size)  \n    return img\n\ndef imshow_single(img):\n    img = img.numpy()  \n    plt.imshow(np.transpose(img, (1, 2, 0)))  # (CxHxW --> HxWxC)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train set\ntrain_set = datasets.ImageFolder(root=fish_dataset_train_dir, transform=train_transforms)\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n\n# Test set    \ntest_set = TestFishDataset(data_dir=fish_dataset_test_dir, transforms=test_transforms)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers =4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nprint(\"Training set:\\n\")   \nimage, label = train_set[random.randint(0, 149)] \nimage = denormalize_and_resize(image)\nimshow_single(image)\nprint(f'Label: {label}')\n\nprint(\"\\nTest set:\\n\")\nimage,names = test_set[random.randint(0, 147)]  \nimage = denormalize_and_resize(image)\nimshow_single(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\n\ndef train(net, loaders, optimizer, criterion, epochs=100, dev=torch.device('cpu')):\n    best_val_loss = float('inf') \n    best_val_accuracy = float('-inf') \n    try:\n        net = net.to(dev)\n        \n        # Initialize history\n        history_loss = {\"train\": [], \"val\": []}\n        history_accuracy = {\"train\": [], \"val\": []}\n        \n        # Process each epoch\n        for epoch in range(epochs):\n            \n            # Initialize epoch variables\n            sum_loss = {\"train\": 0, \"val\": 0}\n            sum_accuracy = {\"train\": 0, \"val\": 0}\n            \n            # Process each split\n            for split in [\"train\", \"val\"]:\n                if split == \"train\":\n                    net.train()\n                else:\n                    net.eval()\n                    \n                # Process each batch\n                for (input, labels) in loaders[split]:\n                   \n                    input = input.to(dev)\n                    labels = labels.to(dev)\n                    # Reset gradients\n                    optimizer.zero_grad()\n                    # Compute output\n                    if split == \"train\":\n                        outputs = net(input)\n                    else:\n                        with torch.no_grad():\n                            outputs = net(input)\n                    loss = criterion(outputs, labels)\n                    \n                    # Update loss\n                    sum_loss[split] += loss.item()\n                    \n                    # Check parameter update\n                    if split == \"train\":\n                        # Compute gradients\n                        loss.backward()\n                        # Optimize\n                        optimizer.step()\n                        \n                    # Compute accuracy\n                    preds = torch.argmax(outputs, 1) # 1 is the second dimension                    \n                    batch_accuracy = (preds == labels).sum().item() / input.size(0)\n                    \n                    # Update accuracy\n                    sum_accuracy[split] += batch_accuracy\n                    \n            # Compute epoch loss/accuracy\n            epoch_loss = {split: sum_loss[split] / len(loaders[split]) for split in [\"train\", \"val\"]}\n            epoch_accuracy = {split: sum_accuracy[split] / len(loaders[split]) for split in [\"train\", \"val\"]}\n\n            # Model selection\n            if epoch_loss[\"val\"] < best_val_loss:\n                torch.save({\n                    \"epoch\": epoch,\n                    \"model_state_dict\": net.state_dict(),\n                    \"optimizer_state_dict\": optimizer.state_dict(),\n                    \"val_loss\": epoch_loss['val']\n                }, './best_loss.pt')\n                best_val_loss = epoch_loss['val']\n                \n            # Model selection    \n            if epoch_accuracy[\"val\"] > best_val_accuracy:\n                torch.save({\n                \"epoch\": epoch,\n                \"model_state_dict\": net.state_dict(),\n                \"optimizer_state_dict\": optimizer.state_dict(),\n                \"val_accuracy\": epoch_accuracy[\"val\"]\n                }, './best_accuracy.pt')\n                best_val_accuracy = epoch_accuracy[\"val\"]\n\n            # Update history\n            for split in [\"train\", \"val\"]:\n                history_loss[split].append(epoch_loss[split])\n                history_accuracy[split].append(epoch_accuracy[split])\n                \n            # Print info\n            print(f\"Epoch {epoch+1}:\",\n                  f\"TrL={epoch_loss['train']:.4f},\",\n                  f\"TrA={epoch_accuracy['train']:.4f},\",\n                  f\"VL={epoch_loss['val']:.4f},\",\n                  f\"VA={epoch_accuracy['val']:.4f}\")\n    except KeyboardInterrupt:\n        print(\"Interrupted\")\n    finally:\n        \n        # Plot loss\n        plt.title(\"Loss\")\n        for split in [\"train\", \"val\"]:\n            plt.plot(history_loss[split], label=split)\n        plt.legend()\n        plt.show()\n        \n        # Plot accuracy\n        plt.title(\"Accuracy\")\n        for split in [\"train\", \"val\"]:\n            plt.plot(history_accuracy[split], label=split)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = datasets.ImageFolder(root=fish_dataset_train_dir, transform=train_transforms)\n\nval_idx = []\ntrain_idx = []\ncounter = 0\nidx = 0\n\nfor img,label in train_set:\n    if counter < 2:\n        val_idx.append(idx)\n    else:\n        train_idx.append(idx)\n    idx += 1\n    counter +=1\n    \n    if counter == 10:\n        counter = 0\n\n\nprint (\"validation set length: \",len(val_idx)) # 30\nprint (\"\\n validation set indices: \\n\",val_idx) # [0, 1, 10, 11, 20, 21, 30, 31, 40, 41, 50, 51, ... , 140, 141]\nprint (\"\\ntraing set length: \",len(train_idx)) # 120\n\n\nfrom torch.utils.data import Subset\n\nval_set = Subset(train_set, val_idx) \ntrain_set = Subset(train_set, train_idx)   \n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\nval_loader   = DataLoader(val_set,   batch_size=15, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers =4)\n\nloaders = {\n    \"train\": train_loader,\n    \"val\": val_loader\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet18, ResNet18_Weights\nimport torch.nn as nn\n\nmy_resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT) \nnew_classifier = nn.Linear(my_resnet18.fc.in_features, 15)\n\nmy_resnet18.fc = new_classifier \n\nfor param in my_resnet18.parameters():\n    param.requires_grad = False\n\nfor param in my_resnet18.fc.parameters():\n    param.requires_grad = True\n    \nimport torch.optim as optim\nresnet18_optimizer = optim.Adam(my_resnet18.parameters(), lr = 0.01)\ncriterion = nn.CrossEntropyLoss()\n\ndev = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nprint(dev)\n\nprint(\"\\nTraining...\\n\")\ntrain(my_resnet18, loaders, resnet18_optimizer, criterion, epochs=30, dev=dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_and_save_predictions(net, test_loader, output_file=\"submission.csv\", device=torch.device('cpu')):\n    net = net.to(device)\n    net.eval()\n    \n    predictions = []\n    image_names = []\n\n    with torch.no_grad():\n        for inputs, img_names in test_loader:\n            inputs = inputs.to(device)\n            outputs = net(inputs)\n            preds = torch.argmax(outputs, 1).cpu().numpy()\n            predictions.extend(preds)\n            image_names.extend(img_names)\n    \n    # Create a DataFrame and save to CSV\n    df = pd.DataFrame({\"image\": image_names, \"class\": predictions})\n    df.to_csv(output_file, index=False)\n    print(f\"Predictions saved to {output_file}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model1_best_accuracy.pt', map_location=torch.device(dev))\nmy_resnet18.load_state_dict(checkpoint['model_state_dict'])\n\nevaluate_and_save_predictions(my_resnet18, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL 2**\n**We train an autoencoder with a classifier on the large unannotated dataset and the small annotated dataset**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass AutoencoderClassifier(nn.Module):\n    def __init__(self, num_classes=15):\n        super(AutoencoderClassifier, self).__init__()\n        \n       # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), # 224x224 => 112x112\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), # 112x112 => 56x56\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), # 56x56 => 28x28\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 28x28 => 56x56\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 56x56 => 112x112\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # 112x112 => 224x224\n            nn.Sigmoid()\n        )\n        \n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 28 * 28, 512),  \n            nn.ReLU(),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        flattened = encoded.view(encoded.size(0), -1)\n        prediction = self.classifier(flattened)\n        return decoded, prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unannotated fish dataset\nunlabeled_dir = \"/kaggle/input/unannotated-dataset/images_all\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UnlabledDataset(Dataset):\n    def __init__(self, data_dir, transforms=None):\n        self.data_dir = Path(data_dir)\n        self.transforms = transforms\n        self.files = sorted(os.listdir(self.data_dir))\n        \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, i):\n        file_path = self.data_dir / self.files[i]\n        img = Image.open(file_path).convert(\"RGB\")\n        if self.transforms is not None:\n            img = self.transforms(img)\n        return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unlabeled set \nunlabeled_set = UnlabledDataset(data_dir =unlabeled_dir, transforms=train_transforms)\n\nunlabeled_train_idx = list(range(len(unlabeled_set))) \nimport random\nrandom.shuffle(unlabeled_train_idx)\nunlabeled_num_train = len(unlabeled_set) - int(len(unlabeled_set) * 0.2) \nunlabeled_val_idx = unlabeled_train_idx[unlabeled_num_train:] \nunlabeled_train_idx = unlabeled_train_idx[:unlabeled_num_train] \n\nfrom torch.utils.data import Subset  \n\nunlabeled_val_set = Subset(unlabeled_set, unlabeled_val_idx) \nunlabeled_set = Subset(unlabeled_set, unlabeled_train_idx)\n\nunlabeled_loader = DataLoader(unlabeled_set, batch_size=128, shuffle=True,num_workers = 4)\nunlabeled_val_loader = DataLoader(unlabeled_val_set,batch_size=128, shuffle=False, num_workers = 4)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers = 4)\n\nunlabeled_loaders = {\n    \"train\": unlabeled_loader,\n    \"val\": unlabeled_val_loader\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_autoencoder_with_classifier(net,unlabeled_loaders,loaders,optimizer,criterion,criterion_autoencoder,epochs=100,dev=torch.device('cpu')):\n    best_val_loss = float('inf')  \n    best_val_accuracy = float('-inf')\n    try:\n        net = net.to(dev)\n        # Initialize history\n        history_loss_classification = {\"train\": [], \"val\": []}\n        history_loss_reconstruction = {\"train\": [], \"val\": []}\n        history_classification_accuracy = {\"train\": [], \"val\": []}\n\n        # Process each epoch\n        for epoch in range(epochs):\n            sum_loss_classification = {\"train\": 0, \"val\": 0}\n            sum_loss_reconstruction = {\"train\": 0, \"val\": 0}\n            sum_accuracy_classification = {\"train\": 0, \"val\": 0}\n\n            for split in [\"train\", \"val\"]:\n                _ = net.train() if split == \"train\" else net.eval()\n                \n                for input in unlabeled_loaders[split]:\n                    input = input.to(dev)\n                    optimizer.zero_grad()\n                    \n                    if split == \"train\":\n                        decoded_outputs, _ = net(input)\n                    else:\n                        with torch.no_grad():\n                            decoded_outputs, _ = net(input)\n                            \n                    loss_autoencoder = criterion_autoencoder(decoded_outputs, input)\n                    sum_loss_reconstruction[split] += loss_autoencoder.item()\n            \n                    if split == 'train':\n                        loss_autoencoder.backward()\n                        optimizer.step()\n\n                for input, labels in loaders[split]:\n                    input = input.to(dev)\n                    labels = labels.to(dev)\n                    optimizer.zero_grad()\n\n                    if split == \"train\":\n                        _,preds_outputs = net(input)\n                    else:\n                        with torch.no_grad():\n                            _,preds_outputs = net(input)\n                    \n                    loss_classification = criterion(preds_outputs, labels)\n                    sum_loss_classification[split] += loss_classification.item()\n                    \n                    if split == 'train':\n                        loss_classification.backward()\n                        optimizer.step()\n                        \n                    preds = torch.argmax(preds_outputs, 1)\n                    batch_accuracy = (preds == labels).sum().item() / input.size(0)\n                    sum_accuracy_classification[split] += batch_accuracy\n             \n            epoch_loss_classification = {split: sum_loss_classification[split] / len(loaders[split]) for split in [\"train\", \"val\"]}\n            epoch_loss_reconstruction = {split: sum_loss_reconstruction[split] / len(unlabeled_loaders[split]) for split in [\"train\", \"val\"]}\n            epoch_accuracy_classification = {split: sum_accuracy_classification[split] / len(loaders[split]) for split in [\"train\", \"val\"]}\n\n            # Model selection\n            if epoch_loss_classification[\"val\"] < best_val_loss:\n                torch.save({\n                    \"epoch\": epoch,\n                    \"model_state_dict\": net.state_dict(),\n                    \"optimizer_state_dict\": optimizer.state_dict(),\n                    \"val_loss\": epoch_loss_classification['val']\n                }, './best_loss.pt')\n                best_val_loss = epoch_loss_classification['val']  \n                \n            # Model selection    \n            if epoch_accuracy_classification[\"val\"] > best_val_accuracy:\n                torch.save({\n                    \"epoch\": epoch,\n                    \"model_state_dict\": net.state_dict(),\n                    \"optimizer_state_dict\": optimizer.state_dict(),\n                    \"val_accuracy\": epoch_accuracy_classification[\"val\"]\n                }, './best_accuracy.pt')\n                best_val_accuracy = epoch_accuracy_classification[\"val\"]\n            \n            for split in [\"train\", \"val\"]:\n                history_loss_classification[split].append(epoch_loss_classification[split])\n                history_loss_reconstruction[split].append(epoch_loss_reconstruction[split])\n                history_classification_accuracy[split].append(epoch_accuracy_classification[split])\n\n            # Print classification info\n            print(f\"Epoch {epoch+1}:\",\n                  f\"TrRL={epoch_loss_reconstruction['train']:.4f},\",\n                  f\"RVL={epoch_loss_reconstruction['val']:.4f},\",\n                  f\"TrL={epoch_loss_classification['train']:.4f},\",\n                  f\"TrA={epoch_accuracy_classification['train']:.4f},\",\n                  f\"VL={epoch_loss_classification['val']:.4f},\",\n                  f\"VA={epoch_accuracy_classification['val']:.4f}\"\n                  \n                 )\n    except KeyboardInterrupt:\n        print(\"Interrupted\")\n    finally:\n        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n\n        ax1.plot(history_loss_reconstruction[\"train\"], label='Train Reconstruction')\n        ax1.plot(history_loss_reconstruction[\"val\"], label='Val Reconstruction')\n        ax1.set_title(\"Reconstruction loss\")\n        ax1.set_xlabel(\"Epoch\")\n        ax1.set_ylabel(\"Loss\")\n        ax1.legend()\n\n        ax2.plot(history_classification_accuracy[\"train\"], label='Train Accuracy')\n        ax2.plot(history_classification_accuracy[\"val\"], label='Val Accuracy')\n        ax2.set_title(\"Classification accuracy\")\n        ax2.set_xlabel(\"Epoch\")\n        ax2.set_ylabel(\"Accuracy\")\n        ax2.legend()\n\n        ax3.plot(history_loss_classification[\"train\"], label='Train Classification')\n        ax3.plot(history_loss_classification[\"val\"], label='Val Classification')\n        ax3.set_title(\"Classification loss\")\n        ax3.set_xlabel(\"Epoch\")\n        ax3.set_ylabel(\"Loss\")\n        ax3.legend()\n\n        plt.tight_layout() \n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auto_encoder_with_classifier = AutoencoderClassifier()\noptimizer_aec = torch.optim.Adam(auto_encoder_with_classifier.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\ncriterion_autoencoder = nn.MSELoss()\ndev = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nprint(dev)\n\n# Train\nprint(\"\\nTraining: ...\\n\")\ntrain_autoencoder_with_classifier(auto_encoder_with_classifier, unlabeled_loaders, loaders, optimizer_aec, criterion, criterion_autoencoder, epochs=40, dev = dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model2_best_accuracy.pt', map_location=torch.device(dev))\nauto_encoder_with_classifier.load_state_dict(checkpoint['model_state_dict'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\n\n# we want to compare an original image sample with the reconstruced one\nimages, labels = next(iter(val_loader))\nauto_encoder_with_classifier = auto_encoder_with_classifier.to('cpu')\n\nrec_images, preds = auto_encoder_with_classifier(images)\n\nimages = denormalize_and_resize(images)\nimage_np = images.cpu().detach().numpy()\nimage_np = np.transpose(image_np, (0, 2, 3, 1))  \n\nrec_images = denormalize_and_resize(rec_images)\n\nrec_image_np = rec_images.cpu().detach().numpy()\nrec_image_np = np.transpose(rec_image_np, (0, 2, 3, 1))  \n\n\nprint(\"Original Image:\\n\")\nplt.imshow(image_np[0]) \nplt.show()\nprint(\"Original Image Label: \",labels[0].item())\n\nprint(\"\\nReconstructed Image:\")\nplt.imshow(rec_image_np[0])  \nplt.show()\nprint(\"\\nReconstructed Image Label: \",torch.argmax(preds[0]).item())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autoencoder_evaluation_and_save_predictions(net, test_loader, output_file=\"submission.csv\", device=torch.device('cpu')):\n    net = net.to(device)\n    net.eval()\n    \n    predictions = []\n    image_names = []\n\n    with torch.no_grad():\n        for inputs, img_names in test_loader:\n            inputs = inputs.to(device)\n            _,outputs = net(inputs)\n            preds = torch.argmax(outputs, 1).cpu().numpy()\n            predictions.extend(preds)\n            image_names.extend(img_names)\n    \n    # Create a DataFrame and save to CSV\n    df = pd.DataFrame({\"image\": image_names, \"class\": predictions})\n    df.to_csv(output_file, index=False)\n    print(f\"Predictions saved to {output_file}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder_evaluation_and_save_predictions(auto_encoder_with_classifier, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL 3**\n\n**We created pseudo-labels with the autoencoder and performed classification with two training steps on ResNet50**","metadata":{}},{"cell_type":"code","source":"# unlabeled set \nunlabeled_set = UnlabledDataset(data_dir =unlabeled_dir, transforms=test_transforms) # same test transforms\nunlabeled_loader = DataLoader(unlabeled_set, batch_size = 64, shuffle =True, num_workers = 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PseudoLabeledDataset(Dataset):\n    def __init__(self, data, transforms=T.Compose([])):\n        self.data = data\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        input_image, label = self.data[idx]\n        input_image = self.transforms(input_image)\n        return input_image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef aec_evaluate_and_get_pseudolabels(net, unlabeled_loader, device=torch.device('cpu')):\n    net = net.to(device)\n    net.eval()\n    \n    pseudo_labeled_list = []\n    total_batches = len(unlabeled_loader)\n    \n    with torch.no_grad():\n        for batch_idx, inputs in tqdm(enumerate(unlabeled_loader), total=total_batches, desc=\"Generating Pseudo-Labels\"):\n            inputs = inputs.to(device)\n            _,outputs = net(inputs)\n            probs = torch.softmax(outputs, dim=1)\n            preds = torch.argmax(probs, 1).cpu().numpy()\n            max_probs = torch.max(probs, dim=1)[0].cpu().numpy() \n            for input_image, prediction, confidence  in zip(inputs, preds, max_probs):\n                if confidence >= 0.8:\n                    pseudo_labeled_list.append((input_image.cpu(), prediction))\n                \n\n    return pseudo_labeled_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model2_best_accuracy.pt', map_location=torch.device(dev))\nauto_encoder_with_classifier.load_state_dict(checkpoint['model_state_dict'])\n\npseudo_labeled_list = aec_evaluate_and_get_pseudolabels(auto_encoder_with_classifier, unlabeled_loader,device = dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pseudo_labeled_transforms = T.Compose([\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomRotation(degrees=(45)),\n        T.Resize((224,224)),\n        T.Normalize(0.5, 0.5)\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\npseudo_labeled_set = PseudoLabeledDataset(pseudo_labeled_list, transforms = pseudo_labeled_transforms)\ncombined_set = ConcatDataset([train_set, pseudo_labeled_set])\nprint(len(pseudo_labeled_set))\nprint(len(combined_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = combined_set[(len(combined_set) - 1)] \nimage = denormalize_and_resize(image)\nimshow_single(image)\nprint(f'Label: {label}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_train_idx = list(range(len(combined_set))) \n\nimport random\nrandom.shuffle(combined_train_idx)\ncombined_num_train = len(combined_set) - int(len(combined_set) * 0.25) \ncombined_val_idx = combined_train_idx[combined_num_train:] \ncombined_train_idx = combined_train_idx[:combined_num_train] \n\nfrom torch.utils.data import Subset  \n\ncombined_val_set = Subset(combined_set, combined_val_idx) \ncombined_set = Subset(combined_set, combined_train_idx)\n\ncombined_loader = DataLoader(combined_set, batch_size=64, shuffle=True,num_workers = 4)\ncombined_val_loader   = DataLoader(combined_val_set,   batch_size=64, shuffle=False, num_workers = 4)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers = 4)\n\ncombined_loaders = {\n    \"train\": combined_loader,\n    \"val\": combined_val_loader\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First, we trained the pre-trained ResNet50 on the combined dataset.**","metadata":{}},{"cell_type":"code","source":"from torchvision.models import resnet50, ResNet50_Weights\n\nmy_resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)\nmy_resnet50.fc = nn.Linear(my_resnet50.fc.in_features, 15)  \n\nresnet50_optimizer = optim.Adam(my_resnet50.parameters(), lr=0.00001)\n\nprint(\"\\nTraining...\\n\")\ntrain(my_resnet50, combined_loaders, resnet50_optimizer, criterion, epochs=25, dev=dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Then we fine-tuned the classifier using the small annotated dataset.**","metadata":{}},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model3_first_training_best_accuracy.pt', map_location=torch.device(dev))\nmy_resnet50.load_state_dict(checkpoint['model_state_dict'])\n\nfor param in my_resnet50.parameters():\n    param.requires_grad = False\n\nfor param in my_resnet50.fc.parameters():\n    param.requires_grad = True\n\nresnet50_optimizer = optim.Adam(my_resnet50.parameters(), lr=0.01)\n\ntrain(my_resnet50, loaders, resnet50_optimizer, criterion, epochs=30, dev=dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model3_second_training_best_accuracy.pt', map_location=torch.device(dev))\nmy_resnet50.load_state_dict(checkpoint['model_state_dict'])\n\nevaluate_and_save_predictions(my_resnet50, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model-4**\n**We utilized pseudo-labels to perform classification with two training steps on ResNet18**","metadata":{}},{"cell_type":"markdown","source":"**First, we trained the pre-trained ResNet18 on the combined dataset.**","metadata":{}},{"cell_type":"code","source":"my_resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT) \nnew_classifier = nn.Linear(my_resnet18.fc.in_features, 15)\nmy_resnet18.fc = new_classifier \n\nresnet18_optimizer = optim.Adam(my_resnet18.parameters(), lr=0.00001)\n\n# Training on the combined set\nprint(\"\\nTraining: ...\\n\")\ntrain(my_resnet18, combined_loaders, resnet18_optimizer, criterion, epochs=25, dev=dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Then we fine-tuned the classifier using the small annotated dataset.**","metadata":{}},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model4_first_training_best_accuracy.pt', map_location=torch.device(dev))\nmy_resnet18.load_state_dict(checkpoint['model_state_dict'])\n\nfor param in my_resnet18.parameters():\n    param.requires_grad = False\n\nfor param in my_resnet18.fc.parameters():\n    param.requires_grad = True\n    \nresnet18_optimizer = optim.Adam(my_resnet18.parameters(), lr=0.01)\n\n# Train\nprint(\"\\nTraining: ...\\n\")\ntrain(my_resnet18, loaders, resnet18_optimizer, criterion, epochs=30, dev=dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/Model4_second_training_best_accuracy.pt', map_location=torch.device(dev))\nmy_resnet18.load_state_dict(checkpoint['model_state_dict'])\nevaluate_and_save_predictions(my_resnet18, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}